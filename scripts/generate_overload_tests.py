"""
Script to generate Python typecheck test files for all possible ABI type string argument combinations.

Usage:
    python scripts/generate_overload_tests.py [--impl codec|abi|both]

This will overwrite test files in:
- tests/typecheck/codec/decode/fixed/len_1/overload_test_data_*.py (tuple-based)
- tests/typecheck/codec/decode/fixed/len_2/overload_test_data_*.py
- tests/typecheck/codec/decode/fixed/len_3/overload_test_data_*.py
- tests/typecheck/codec/decode/variable/len_1/overload_test_data_*.py (iterable-based)
- tests/typecheck/codec/decode/variable/len_2/overload_test_data_*.py
- tests/typecheck/codec/decode/variable/len_3/overload_test_data_*.py
- tests/typecheck/abi/decode/fixed/len_1/overload_test_data_*.py (tuple-based, abi.decode)
- tests/typecheck/abi/decode/variable/len_1/overload_test_data_*.py (iterable-based, abi.decode)
...

Test files are chunked in 10,000-case intervals.

Key features:
- Streams generation: cases are written chunk-by-chunk, not all held in memory.
- Progress bar (tqdm) measures chunk files, not individual cases.
- For TupleXXXIntTypeStr, only 10 representative values are sampled (ending with int8, int16, int64, int128, int256, and their uint variants).
- Each chunk's lines are collected and written in a single operation for efficiency.
- Covers: all int, uint, bytes, bool, string, arrays, and all possible combinations up to length 3, including fallback/unknown types in all permutations.
- If you add new ABI type strings, rerun this script to update the test files.
"""

import argparse
import itertools
import math
import pathlib
import re
import sys
from typing import (
    Any,
    Dict,
    Final,
    ForwardRef,
    Iterator,
    List,
    Literal,
    Set,
    Tuple,
    Union,
    get_args,
    get_origin,
)

from tqdm import (
    tqdm,
)
from typing_extensions import (
    LiteralString,
)

MAX_LEN_FIXED: Final = 3
MAX_LEN_VARIABLE: Final = 4
CHUNK_SIZE: Final = 10_000
FILENAME_PREFIX: Final = "overload_test_data_"
VARIATIONS_PER_TYPE_COMBO: Final = 2

ANY_ALIAS: Final = "A"
ASSERT_TYPE_ALIAS: Final = "ck"
BOOL_ALIAS: Final = "bo"
BYTES_ALIAS: Final = "by"
DATA_ALIAS: Final = "D"
FUNC_ALIAS: Final = "f"
HEXADDRESS_ALIAS: Final = "HA"
INT_ALIAS: Final = "i"
STR_ALIAS: Final = "s"
TUPLE_ALIAS: Final = "T"
UNION_ALIAS: Final = "U"


INHEADER_CODEC = f"""# AUTOGENERATED: Run scripts/generate_overload_tests.py to update.
# Requires mypy extras
# To run: pip install mypy && mypy tests/typecheck

# alias some things so we can minimize test data size in source control
from typing import Any as {ANY_ALIAS}
from typing import Tuple as {TUPLE_ALIAS}
from typing import Union as {UNION_ALIAS}
from typing_extensions import assert_type as {ASSERT_TYPE_ALIAS}
from eth_typing import HexAddress as {HEXADDRESS_ALIAS}
from faster_eth_abi.codec import ABIDecoder
from faster_eth_abi.registry import ABIRegistry

# more aliases to save a bunch more chars
{BOOL_ALIAS} = bool
{BYTES_ALIAS} = bytes
{INT_ALIAS} = int
{STR_ALIAS} = str

decoder = ABIDecoder(ABIRegistry())

# the callable we are checking
{FUNC_ALIAS} = decoder.decode

# input data
{DATA_ALIAS} = b"\\x00" * 32
"""

HEADER_ABI = f"""# AUTOGENERATED: Run scripts/generate_overload_tests.py to update.
# Requires mypy extras
# To run: pip install mypy && mypy tests/typecheck

# alias some things so we can minimize test data size in source control
from typing import Any as {ANY_ALIAS}
from typing import Tuple as {TUPLE_ALIAS}
from typing import Union as {UNION_ALIAS}
from typing_extensions import assert_type as {ASSERT_TYPE_ALIAS}
from eth_typing import HexAddress as {HEXADDRESS_ALIAS}
from faster_eth_abi import abi

# more aliases to save a bunch more chars
{BOOL_ALIAS} = bool
{BYTES_ALIAS} = bytes
{INT_ALIAS} = int
{STR_ALIAS} = str

# the callable we are checking
{FUNC_ALIAS} = abi.decode

# input data
{DATA_ALIAS} = b"\\x00" * 32
"""

RETURN_TYPE_MAP = {
    "address": HEXADDRESS_ALIAS,
    "address[]": ANY_ALIAS,  # f"{TUPLE_ALIAS}[{HEXADDRESS_ALIAS}, ...]",
    "bytes": BYTES_ALIAS,
    "bytes[]": ANY_ALIAS,  # f"{TUPLE_ALIAS}[{BYTES_ALIAS}, ...]",
    "string": STR_ALIAS,
    "string[]": ANY_ALIAS,  # f"{TUPLE_ALIAS}[{STR_ALIAS}, ...]",
    "int": INT_ALIAS,
    "bool": BOOL_ALIAS,
    "bool[]": ANY_ALIAS,  # f"{TUPLE_ALIAS}[{BOOL_ALIAS}, ...]",
    "?": ANY_ALIAS,
}
for i in range(8, 257, 8):
    RETURN_TYPE_MAP[f"int{i}"] = INT_ALIAS
    RETURN_TYPE_MAP[f"uint{i}"] = INT_ALIAS
    RETURN_TYPE_MAP[f"int{i}[]"] = f"{TUPLE_ALIAS}[{INT_ALIAS}, ...]"
    RETURN_TYPE_MAP[f"uint{i}[]"] = f"{TUPLE_ALIAS}[{INT_ALIAS}, ...]"
for i in range(1, 33):
    RETURN_TYPE_MAP[f"bytes{i}"] = BYTES_ALIAS
    RETURN_TYPE_MAP[f"bytes{i}[]"] = f"{TUPLE_ALIAS}[{BYTES_ALIAS}, ...]"


def build_alias_map() -> Dict[str, Any]:
    sys.path.insert(0, str(pathlib.Path(__file__).parent.parent))
    import faster_eth_abi.typing

    alias_map = {}
    for name in dir(faster_eth_abi.typing):
        if not name.startswith("_"):
            obj = getattr(faster_eth_abi.typing, name)
            alias_map[name] = obj
    return alias_map


def all_integers_in_set(s: str, allowed: Set[int]) -> bool:
    """
    Parses the input string for all integer values (including negative numbers)
    and returns True if all found integers are members of the allowed set.
    """
    found = {int(x) for x in re.findall(r"-?\d+", s)}
    return found.issubset(allowed)


def extract_all_literals(typ, alias_map, alias_path=None):
    if alias_path is None:
        alias_path = []
    if typ is str:
        raise ValueError(
            f"Encountered plain 'str' type in alias path: {' -> '.join(alias_path)}."
        )
    origin = get_origin(typ)
    if origin is Union:
        for arg in get_args(typ):
            yield from extract_all_literals(arg, alias_map, alias_path)
        return
    elif origin is Literal:
        if alias_path[-1] in ("BytesArrayTypeStr", "IntArrayTypeStr"):
            # TODO: we need to implement overloads for these, for now we only have the literals defined
            print(f"skipping {alias_path}")
            return
        if alias_path[-1].startswith("Tuple") and alias_path[-1].endswith("IntTypeStr"):
            # for now, we will exclude these. We need to implement them
            # in the actual overloads, which takes a new script. stay tuned.
            return
            for value in get_args(typ):
                if all_integers_in_set(value, {8, 16, 64, 128, 256}):
                    if value not in RETURN_TYPE_MAP:
                        parentheses_stripped = value[1:-1]
                        types = parentheses_stripped.split(",")
                        RETURN_TYPE_MAP[
                            value
                        ] = f"{TUPLE_ALIAS}[{', '.join(RETURN_TYPE_MAP[t] for t in types)}]"
                    yield value
            return
        else:
            yield from get_args(typ)
    elif isinstance(typ, ForwardRef):
        ref_name = typ.__forward_arg__
        if ref_name in alias_map:
            yield from extract_all_literals(
                alias_map[ref_name], alias_map, alias_path + [ref_name]
            )
            return
        raise RuntimeError(
            f"ForwardRef {ref_name!r} not found in alias map (path: {' -> '.join(alias_path)})"
        )
    else:
        raise RuntimeError(
            f"Type {typ!r} is not a Union, Literal, ForwardRef, or str (origin={origin!r}, path: {' -> '.join(alias_path)})"
        )


def expand_literal_values():
    alias_map = build_alias_map()
    alias_names = [
        "AddressTypeStr",
        "BytesTypeStr",
        "StringTypeStr",
        "IntegerTypeStr",
        "BoolTypeStr",
        "ArrayTypeStr",
        "TupleTypeStr",
        "DecodesToIntTypeStr",
    ]
    for name in sorted(alias_names):
        if name == "DecodesToIntTypeStr":
            from faster_eth_abi.codec import (
                DecodesToIntTypeStr,
            )

            typ = DecodesToIntTypeStr
        else:
            typ = alias_map[name]
        yield name, map(str, extract_all_literals(typ, alias_map, [name]))


def get_all_literals() -> List["LiteralString"]:
    all_literals = set()
    for _name, literal_values in expand_literal_values():
        all_literals.update(literal_values)
    return sorted(all_literals) + ["?"]


def get_expected_type_tuple(types: Tuple[str, ...]) -> str:
    py_types = [ANY_ALIAS if t == "?" else RETURN_TYPE_MAP[t] for t in types]
    return f"{TUPLE_ALIAS}[{', '.join(py_types)}]"


def get_expected_type_iterable(types: Tuple[str, ...]) -> str:
    py_types = [ANY_ALIAS if t == "?" else RETURN_TYPE_MAP[t] for t in types]
    unique_types = sorted(set(py_types))
    if ANY_ALIAS in unique_types:
        return f"{TUPLE_ALIAS}[{ANY_ALIAS}, ...]"
    elif len(unique_types) == 1:
        return f"{TUPLE_ALIAS}[{unique_types[0]}, ...]"
    else:
        return f"{TUPLE_ALIAS}[{UNION_ALIAS}[{', '.join(unique_types)}], ...]"


def compute_total_cases_sampled(
    all_literals: List["LiteralString"], max_len: int
) -> int:
    n = len(all_literals)
    return sum(n**L for L in range(1, max_len + 1))


def compute_total_chunks(all_literals: List["LiteralString"], max_len: int) -> int:
    total_cases = compute_total_cases_sampled(all_literals, max_len)
    return math.ceil(total_cases / CHUNK_SIZE) * VARIATIONS_PER_TYPE_COMBO


def stream_cases_and_write_files(
    all_literals: List["LiteralString"],
    mode: Literal["tuple", "iterable"],
    impl: Literal["abi", "codec"],
) -> int:
    FOLDER = "fixed" if mode == "tuple" else "variable"
    MAX_LEN = MAX_LEN_FIXED if mode == "tuple" else MAX_LEN_VARIABLE

    case_counter = 0
    total_chunks = compute_total_chunks(all_literals, MAX_LEN)
    total_chunks //= 2  # TODO: fix this
    with tqdm(
        total=total_chunks, desc=f"Streaming {mode} chunks for {impl}"
    ) as progress:
        for L in range(1, MAX_LEN + 1):
            PATH_WITHOUT_NUMBER = (
                f"tests/typecheck/{impl}/decode/{FOLDER}/len_{L}/{FILENAME_PREFIX}"
            )
            chunk_idx = 1
            chunk_lines = []
            file_counter = 0

            def format_case(typestr: str, expected: str) -> str:
                nonlocal case_counter, file_counter
                case = f"{ASSERT_TYPE_ALIAS}({FUNC_ALIAS}({typestr}, {DATA_ALIAS}), {expected})  # {mode} case {case_counter}\n"
                case_counter += 1
                file_counter += 1
                return case

            if mode == "tuple":

                def addline(case: Tuple[str, ...]) -> Iterator[str]:
                    typestr = (
                        f"('{case[0]}',)"
                        if len(case) == 1
                        else f"({', '.join(map(repr, case))})"
                    )
                    expected = get_expected_type_tuple(case)
                    chunk_lines.append(format_case(typestr, expected))
                    # chunk_lines.append(format_case("ABICodec.decode", f"codec, {typestr}", expected)
                    # chunk_lines.append(format_case("ABIDecoder.decode", f"codec, {typestr}", expected)
                    # chunk_lines.append(format_case("ABIDecoder.decode", f"decoder, {typestr}", expected)

            else:

                def addline(case: Tuple[str, ...]) -> Iterator[str]:
                    typestr = f"[{', '.join(map(repr, case))}]"
                    expected = get_expected_type_iterable(case)
                    chunk_lines.append(format_case(typestr, expected))
                    # chunk_lines.append(format_case("ABICodec.decode", f"codec, {typestr}", expected)
                    # chunk_lines.append(format_case("ABIDecoder.decode", f"codec, {typestr}", expected)
                    # chunk_lines.append(format_case("ABIDecoder.decode", f"decoder, {typestr}", expected)

            def write_file() -> None:
                nonlocal chunk_idx
                path = pathlib.Path(f"{PATH_WITHOUT_NUMBER}{chunk_idx:05d}.py")
                path.parent.mkdir(parents=True, exist_ok=True)
                with open(path, "w") as f:
                    f.write(HEADER_ABI if impl == "abi" else HEADER_CODEC)
                    f.writelines(chunk_lines)
                chunk_idx += 1
                chunk_lines.clear()
                progress.update(1)

            for combo in itertools.product(all_literals, repeat=L):
                if file_counter and file_counter % CHUNK_SIZE == 0:
                    write_file()
                addline(combo)

            if chunk_lines:
                write_file()

            print(f"finished generating cases for length {L}")

    return case_counter


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--impl", choices=["codec", "abi", "both"], default="both")
    args = parser.parse_args()

    all_literals = get_all_literals()
    print(f"Found {len(all_literals)} ABI type string literals (including fallback).")

    impls = ["codec", "abi"] if args.impl == "both" else [args.impl]
    for impl in impls:
        print(f"Streaming tuple-based test cases for {impl}...")
        stream_cases_and_write_files(all_literals, mode="tuple", impl=impl)
        print(f"Streaming iterable-based test cases for {impl}...")
        stream_cases_and_write_files(all_literals, mode="iterable", impl=impl)

    print("Test generation complete.")


if __name__ == "__main__":
    main()
