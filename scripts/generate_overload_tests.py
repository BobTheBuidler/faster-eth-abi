"""
Script to generate Python typecheck test files for all possible ABI type string argument combinations.

Usage:
    python scripts/generate_overload_tests.py [--impl codec|abi|both]

This will overwrite test files in:
- tests/typecheck/codec/decode/fixed/len_1/overload_test_data_*.py (tuple-based)
- tests/typecheck/codec/decode/fixed/len_2/overload_test_data_*.py
- tests/typecheck/codec/decode/fixed/len_3/overload_test_data_*.py
- tests/typecheck/codec/decode/variable/len_1/overload_test_data_*.py (iterable-based)
- tests/typecheck/codec/decode/variable/len_2/overload_test_data_*.py
- tests/typecheck/codec/decode/variable/len_3/overload_test_data_*.py
- tests/typecheck/abi/decode/fixed/len_1/overload_test_data_*.py (tuple-based, abi.decode)
- tests/typecheck/abi/decode/variable/len_1/overload_test_data_*.py (iterable-based, abi.decode)
...

Test files are chunked in 10,000-case intervals.

Key features:
- Streams generation: cases are written chunk-by-chunk, not all held in memory.
- Progress bar (tqdm) measures chunk files, not individual cases.
- For TupleXXXIntTypeStr, only 10 representative values are sampled (ending with int8, int16, int64, int128, int256, and their uint variants).
- Each chunk's lines are collected and written in a single operation for efficiency.
- Covers: all int, uint, bytes, bool, string, arrays, and all possible combinations up to length 3, including fallback/unknown types in all permutations.
- If you add new ABI type strings, rerun this script to update the test files.
"""

import argparse
import itertools
from math import ceil
from pathlib import Path
import re
import sys
from typing import ForwardRef, Literal, Tuple, Union, get_args, get_origin

from tqdm import tqdm

MAX_LEN_FIXED = 3
MAX_LEN_VARIABLE = 4
CHUNK_SIZE = 10_000
VARIATIONS_PER_TYPE_COMBO = 2

HEADER_CODEC = """# AUTOGENERATED: Run scripts/generate_overload_tests.py to update.
# Requires mypy and Python 3.10+ (for typing.assert_type)
# To run: pip install mypy && mypy tests/typecheck

from typing import Any, Tuple, Union
from typing_extensions import assert_type
from eth_typing import HexAddress
from faster_eth_abi import abi
from faster_eth_abi.codec import ABIDecoder
from faster_eth_abi.registry import ABIRegistry

decoder = ABIDecoder(ABIRegistry())
data = b"\\x00" * 32
"""

HEADER_ABI = """# AUTOGENERATED: Run scripts/generate_overload_tests.py to update.
# Requires mypy and Python 3.10+ (for typing.assert_type)
# To run: pip install mypy && mypy tests/typecheck

from typing import Any, Tuple, Union
from typing_extensions import assert_type
from eth_typing import HexAddress
from faster_eth_abi.abi import decode

data = b"\\x00" * 32
"""

RETURN_TYPE_MAP = {
    "address": "Any",  # "HexAddress", TODO implement me
    "address[]": "Any",  # "Tuple[HexAddress, ...]",
    "bytes": "bytes",
    "bytes[]": "Any",  # "Tuple[bytes, ...]",
    "string": "str",
    "string[]": "Any",  # "Tuple[str, ...]",
    "int": "int",
    "bool": "bool",
    "bool[]": "Tuple[bool, ...]",
    "someothertype": "Any",
}
for i in range(8, 257, 8):
    RETURN_TYPE_MAP[f"int{i}"] = "int"
    RETURN_TYPE_MAP[f"uint{i}"] = "int"
    RETURN_TYPE_MAP[f"int{i}[]"] = "Tuple[int, ...]"
    RETURN_TYPE_MAP[f"uint{i}[]"] = "Tuple[int, ...]"
for i in range(1, 33):
    RETURN_TYPE_MAP[f"bytes{i}"] = "bytes"
    RETURN_TYPE_MAP[f"bytes{i}[]"] = "Tuple[bytes, ...]"


def build_alias_map():
    sys.path.insert(0, str(Path(__file__).parent.parent))
    import faster_eth_abi.typing

    alias_map = {}
    for name in dir(faster_eth_abi.typing):
        if not name.startswith("_"):
            obj = getattr(faster_eth_abi.typing, name)
            alias_map[name] = obj
    return alias_map


def all_integers_in_set(s: str, allowed: set[int]) -> bool:
    """
    Parses the input string for all integer values (including negative numbers)
    and returns True if all found integers are members of the allowed set.
    """
    found = {int(x) for x in re.findall(r"-?\d+", s)}
    return found.issubset(allowed)


def extract_all_literals(typ, alias_map, alias_path=None):
    if alias_path is None:
        alias_path = []
    if typ is str:
        raise ValueError(
            f"Encountered plain 'str' type in alias path: {' -> '.join(alias_path)}."
        )
    origin = get_origin(typ)
    if origin is Union:
        for arg in get_args(typ):
            yield from extract_all_literals(arg, alias_map, alias_path)
        return
    elif origin is Literal:
        if alias_path[-1] in ("BytesArrayTypeStr", "IntArrayTypeStr"):
            # TODO: we need to implement overloads for these, for now we only have the literals defined
            print(f"skipping {alias_path}")
            return
        if alias_path[-1].startswith("Tuple") and alias_path[-1].endswith("IntTypeStr"):
            # for now, we will exclude these. We need to implement them
            # in the actual overloads, which takes a new script. stay tuned.
            return
            for value in get_args(typ):
                if all_integers_in_set(value, {8, 16, 64, 128, 256}):
                    if value not in RETURN_TYPE_MAP:
                        parentheses_stripped = value[1:-1]
                        types = parentheses_stripped.split(",")
                        RETURN_TYPE_MAP[
                            value
                        ] = f"Tuple[{', '.join(RETURN_TYPE_MAP[t] for t in types)}]"
                    yield value
            return
        else:
            yield from get_args(typ)
    elif isinstance(typ, ForwardRef):
        ref_name = typ.__forward_arg__
        if ref_name in alias_map:
            yield from extract_all_literals(
                alias_map[ref_name], alias_map, alias_path + [ref_name]
            )
            return
        raise RuntimeError(
            f"ForwardRef {ref_name!r} not found in alias map (path: {' -> '.join(alias_path)})"
        )
    else:
        raise RuntimeError(
            f"Type {typ!r} is not a Union, Literal, ForwardRef, or str (origin={origin!r}, path: {' -> '.join(alias_path)})"
        )


def expand_literal_values():
    alias_map = build_alias_map()
    alias_names = [
        "AddressTypeStr",
        "BytesTypeStr",
        "StringTypeStr",
        "IntegerTypeStr",
        "BoolTypeStr",
        "ArrayTypeStr",
        "TupleTypeStr",
        "DecodesToIntTypeStr",
    ]
    for name in sorted(alias_names):
        if name == "DecodesToIntTypeStr":
            from faster_eth_abi.codec import (
                DecodesToIntTypeStr,
            )

            typ = DecodesToIntTypeStr
        else:
            typ = alias_map[name]
        yield name, map(str, extract_all_literals(typ, alias_map, [name]))


def get_all_literals():
    all_literals = set()
    for name, literal_values in expand_literal_values():
        all_literals.update(literal_values)
    return sorted(all_literals) + ["someothertype"]

def get_expected_type_tuple(types: Tuple[str, ...]) -> str:
    py_types = ["Any" if t == "someothertype" else RETURN_TYPE_MAP[t] for t in types]
    return f"Tuple[{', '.join(py_types)}]"

def get_expected_type_iterable(types: Tuple[str, ...]) -> str:
    py_types = ["Any" if t == "someothertype" else RETURN_TYPE_MAP[t] for t in types]
    unique_types = sorted(set(py_types))
    if "Any" in unique_types:
        return "Tuple[Any, ...]"
    elif len(unique_types) == 1:
        return f"Tuple[{unique_types[0]}, ...]"
    else:
        return f"Tuple[Union[{', '.join(unique_types)}], ...]"


def compute_total_cases_sampled(all_literals, max_len: int) -> int:
    n = len(all_literals)
    return sum(n**L for L in range(1, max_len + 1))


def compute_total_chunks(all_literals, max_len: int) -> int:
    total_cases = compute_total_cases_sampled(all_literals, max_len)
    return ceil(total_cases / CHUNK_SIZE) * VARIATIONS_PER_TYPE_COMBO


def stream_cases_and_write_files(
    all_literals, mode: Literal["tuple", "iterable"], impl: str
) -> int:
    FOLDER = "fixed" if mode == "tuple" else "variable"
    MAX_LEN = MAX_LEN_FIXED if mode == "tuple" else MAX_LEN_VARIABLE

    case_counter = 0
    total_chunks = compute_total_chunks(all_literals, MAX_LEN)
    progress = tqdm(total=total_chunks, desc=f"Streaming {mode} chunks for {impl}")

    f = None
    for L in range(1, MAX_LEN + 1):
        PATH_WITHOUT_NUMBER = f"tests/typecheck/{impl}/decode/{FOLDER}/len_{L}/{FILENAME_PREFIX}"
        chunk_idx = 1
        chunk_lines = []
        file_counter = 0
        
        def format_case(callee: str, typestr: str, expected: str) -> str:
            nonlocal case_counter, file_counter
            case = f"assert_type({callee}({typestr}, data, {expected}))  # {mode} case {case_counter}\n"
            case_counter += 1
            file_counter += 1
            return case

        def render(case: Tuple[str, ...], mode: Literal["tuple", "iterable"]):
            if mode == "tuple":
                typestr = f"('{case[0]}',)" if len(case) == 1 else f"({', '.join(map(repr, case))})"
                expected = get_expected_type_tuple(case)
            else:
                typestr = f"[{', '.join(map(repr, case))}]"
                expected = get_expected_type_iterable(case)
            
            for callee in ["abi.decode", "decoder.decode"]:
                yield format_case(callee, typestr, expected)
            #yield format_case("ABICodec.decode", f"codec, {typestr}", expected)
            #yield format_case("ABIDecoder.decode", f"codec, {typestr}", expected)
            #yield format_case("ABIDecoder.decode", f"decoder, {typestr}", expected)
        
        for combo in itertools.product(all_literals, repeat=L):
            if file_counter and file_counter % CHUNK_SIZE == 0:
                path = Path(f"{PATH_WITHOUT_NUMBER}{chunk_idx:05d}.py")
                write_file(path, chunk_lines)
                chunk_lines.clear()
                chunk_idx += 1
                if progress:
                    progress.update(1)
            chunk_lines.extend(render(combo, mode=mode))
        print(f"finished generating cases for length {L}")
        if chunk_lines:
            path = Path(f"{PATH_WITHOUT_NUMBER}{chunk_idx:05d}.py")
            write_file(path, chunk_lines)
    if progress:
        progress.close()
    return case_counter

def write_file(path: Path, lines: List[str]) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    with open(path, "w") as f:
        f.write(HEADER)
        f.writelines(lines)
    
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--impl", choices=["codec", "abi", "both"], default="both")
    args = parser.parse_args()

    all_literals = get_all_literals()
    print(f"Found {len(all_literals)} ABI type string literals (including fallback).")

    impls = ["codec", "abi"] if args.impl == "both" else [args.impl]
    for impl in impls:
        print(f"Streaming tuple-based test cases for {impl}...")
        stream_cases_and_write_files(all_literals, mode="tuple", impl=impl)
        print(f"Streaming iterable-based test cases for {impl}...")
        stream_cases_and_write_files(all_literals, mode="iterable", impl=impl)

    print("Test generation complete.")


if __name__ == "__main__":
    main()
