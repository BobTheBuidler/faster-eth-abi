"""
Script to generate a Python typecheck test file for all decode overloads for use with mypy and assert_type.

Usage:
    python scripts/generate_typecheck_codec_overloads_yaml.py

This will overwrite tests/typecheck/test_codec_overloads_typecheck.py with comprehensive assert_type cases
for all supported ABI type strings and overloads. The generated file is used by mypy for robust
type-checking tests.

- Covers: all int, uint, bytes, bool, string, arrays, and a representative sample of tuples.
- If you add new ABI types or overloads, rerun this script to update the test file.
- The generated file may be very large.

"""

import itertools
from pathlib import Path
import re
from typing import get_args

HEADER = """# AUTOGENERATED: Run scripts/generate_typecheck_codec_overloads_yaml.py to update.
# Requires mypy and Python 3.10+ (for typing.assert_type)
# To run: pip install mypy && mypy tests/typecheck/test_codec_overloads_typecheck.py

from typing import Tuple, assert_type
from faster_eth_abi.codec import ABIDecoder
from faster_eth_abi.registry import ABIRegistry

decoder = ABIDecoder(ABIRegistry())
data = b"\\x00" * 32
"""

RETURN_TYPE_MAP = {
    "bytes": "bytes",
    "str": "str",
    "int": "int",
    "bool": "bool",
    "Any": "object",
}


def get_literal_alias_map():
    import sys

    sys.path.insert(0, str(Path(__file__).parent.parent))
    from faster_eth_abi import typing as fabi_typing

    alias_names = [
        "BytesTypeStr",
        "StringTypeStr",
        "IntTypeStr",
        "UintTypeStr",
        "BoolTypeStr",
        "TypeStr",
        "DecodesToIntTypeStr",
    ]
    alias_map = {}
    for name in alias_names:
        if name == "TypeStr":
            from eth_typing.abi import TypeStr as imported_TypeStr

            alias = imported_TypeStr
        elif name == "DecodesToIntTypeStr":
            from faster_eth_abi.codec import DecodesToIntTypeStr

            alias = DecodesToIntTypeStr
        else:
            alias = getattr(fabi_typing, name)
        args = get_args(alias)
        # Flatten nested Unions
        flat = []
        for a in args:
            if hasattr(a, "__origin__") and a.__origin__ is not None:
                flat.extend(get_args(a))
            else:
                flat.append(a)
        alias_map[name] = [str(x) for x in flat]
    return alias_map


def parse_decode_overloads(codec_path):
    """
    Returns a list of overload signatures for decode in codec.py.
    Each signature is a tuple of argument type aliases (e.g., ('BytesTypeStr', 'StringTypeStr'))
    Uses a direct regex: @overload\n\\s+def decode\\(
    """
    text = Path(codec_path).read_text()
    overload_blocks = re.split(r"@overload\n\s+def decode\(", text)[1:]
    signatures = []
    for block in overload_blocks:
        sig = block.split("):", 1)[0]
        m = re.search(r"types:\s*(Tuple|Iterable|Union)?\[(.*?)\]", sig)
        if m:
            inner = m.group(2)
            args = []
            depth = 0
            current = ""
            for c in inner:
                if c == "," and depth == 0:
                    args.append(current.strip())
                    current = ""
                else:
                    if c == "[":
                        depth += 1
                    elif c == "]":
                        depth -= 1
                    current += c
            if current.strip():
                args.append(current.strip())
            # Find return type
            ret = re.search(r"\)\s*->\s*Tuple\[(.*?)\]", block)
            if ret:
                ret_types = tuple(x.strip() for x in ret.group(1).split(","))
            else:
                ret = re.search(r"\)\s*->\s*Tuple\[(.*?)\,\s*\.\.\.\]", block)
                if ret:
                    ret_types = (ret.group(1).strip(), "...")
                else:
                    ret_types = ("Any",)
            signatures.append((tuple(args), ret_types))
        else:
            m2 = re.search(r"types:\s*(\w+)", sig)
            if m2:
                ret = re.search(r"\)\s*->\s*Tuple\[(.*?)\]", block)
                if ret:
                    ret_types = tuple(x.strip() for x in ret.group(1).split(","))
                else:
                    ret_types = ("Any",)
                signatures.append(((m2.group(1),), ret_types))
    return signatures


def expand_aliases(args, alias_map):
    expanded = []
    for arg in args:
        if arg == "TypeStr":
            expanded.append(["__fallback__"])
        elif arg in alias_map and alias_map[arg]:
            expanded.append(alias_map[arg])  # Use all possible values for the Literal
        else:
            expanded.append([arg])
    return list(itertools.product(*expanded))


def main():
    # Step 1: Import Literal definitions and extract values using get_args
    alias_map = get_literal_alias_map()
    # Step 2: Parse all overload signatures in codec.py using direct regex
    signatures = parse_decode_overloads("faster_eth_abi/codec.py")
    print(f"Found {len(signatures)} overload signatures for decode.")
    # Step 3: Expand all combinations using alias_map
    all_cases = []
    for sig, ret_types in signatures:
        expanded = expand_aliases(sig, alias_map)
        for case in expanded:
            all_cases.append((case, ret_types))
    print(f"Total concrete decode cases: {len(all_cases)}")
    # Step 4: Write Python files with all assert_type test cases, split into chunks
    chunk_size = 10000
    total_cases = len(all_cases)
    num_chunks = (total_cases + chunk_size - 1) // chunk_size
    for chunk_idx in range(num_chunks):
        start = chunk_idx * chunk_size
        end = min(start + chunk_size, total_cases)
        filename = f"tests/typecheck/overload_test_data_{chunk_idx+1:04d}.py"
        with open(filename, "w") as f:
            f.write(HEADER)
            for idx, (case, ret_types) in enumerate(all_cases[start:end], start=start):
                typestr = ", ".join(f'"{t}"' for t in case)
                if len(case) == 1:
                    typestr = f"({typestr},)"
                else:
                    typestr = f"({typestr})"
                # Build expected return type
                if "..." in ret_types:
                    expected = (
                        f"Tuple[{RETURN_TYPE_MAP.get(ret_types[0], 'object')}, ...]"
                    )
                else:
                    expected = f"Tuple[{', '.join(RETURN_TYPE_MAP.get(t, 'object') for t in ret_types)}]"
                f.write(
                    f"assert_type(decoder.decode({typestr}, data), {expected})  # case {idx}\n"
                )

    # Step 5: Check that the number of generated tests matches the expected number of expanded cases
    def count_expansions(sig, alias_map):
        count = 1
        for arg in sig:
            if arg == "TypeStr":
                count *= 1  # Only one fallback value
            elif arg in alias_map and alias_map[arg]:
                count *= len(alias_map[arg])
            else:
                count *= 1
        return count

    expected_count = sum(count_expansions(sig, alias_map) for sig, _ in signatures)
    actual_count = len(all_cases)
    if actual_count != expected_count:
        raise RuntimeError(
            f"Test count mismatch: expected {expected_count}, got {actual_count}"
        )
    print(
        f"Wrote {len(all_cases)} assert_type test cases to tests/typecheck/test_codec_overloads_typecheck.py."
    )


if __name__ == "__main__":
    main()
